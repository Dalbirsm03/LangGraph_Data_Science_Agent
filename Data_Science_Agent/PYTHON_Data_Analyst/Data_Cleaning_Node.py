from Data_Science_Agent.STATE.Python_Analyst_State import PythonAnalystState
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import BaseOutputParser,JsonOutputParser
import re
import pandas as pd
from typing import Literal
from pydantic import BaseModel, Field 


def dynamic_sample(df: pd.DataFrame, random_state: int = 42) -> pd.DataFrame:
    """Dynamically sample a DataFrame based on its size.
    
    Args:
        df: Input DataFrame to sample
        random_state: Random seed for reproducibility
        
    Returns:
        Sampled DataFrame with appropriate fraction based on size
    """
    n = len(df)
    frac = 1.0 if n < 10_000 else 0.1 if n < 100_000 else 0.03 if n < 1_000_000 else 0.01
    return df.sample(frac=frac, random_state=random_state)


class PythonOutputParser(BaseOutputParser):
    def parse(self, text: str):
        match = re.search(r"```python(.*?)```", text, re.DOTALL)
        return match.group(1).strip() if match else text
    
class Data_Cleaning_Node:


    def __init__(self,llm):
        self.llm = llm
    
    def cleaning_suggestions(self, state: PythonAnalystState) -> dict:
        """Generate data cleaning suggestions based on data analysis and user query.
        
        Args:
            state: Current state containing raw data and query
            
        Returns:
            Dictionary containing cleaning suggestions
            
        Raises:
            ValueError: If required state components are missing
        """
        if not hasattr(state, 'raw_data') or not state.raw_data:
            raise ValueError("Raw data not found in state")
            
        if not hasattr(state, 'question') or not state.question:
            raise ValueError("User question not found in state")
            
        system_message = """
        You are a data cleaning suggestion agent.

        Your job is to:
        1. Always apply a set of **default best-practice cleaning steps** (listed below).
        2. Carefully analyze the user's question to detect any **custom cleaning intent**.
        3. Suggest **column-specific cleaning** if the user's query implies it (e.g., focusing on dates, cities, prices, etc.).
        4. Return a clear, numbered list of cleaning steps in plain English.

        âš ï¸ You must NOT return:
        - Any code
        - JSON
        - Logs
        - Python functions

        Default cleaning steps (always include these unless the user explicitly says not to):
        - Drop columns with more than 40% missing values.
        - Impute missing numeric values with the column mean.
        - Impute missing categorical values with the column mode.
        - Convert columns to appropriate data types.
        - Remove duplicate rows.
        - Drop rows with any remaining missing values.
        - Remove rows with extreme outliers using the IQR method.

        ### ðŸ” Phase 2: Cleaning Recheck Suggestions (Optional)
        If provided, carefully analyze the additional recheck suggestions below. These are generated by a validation agent after a prior cleaning attempt.

        If this section is **empty**, ignore it.  
        If it **contains suggestions**, act on them as *critical corrections* or *missed steps* that must be addressed.

        ðŸ› ï¸ Recheck Suggestions:
        {cleaning_recheck_suggestions}

        ---

        ### ðŸ§¾ Input Data
        Here is a sample of the dataset:
        {sample_data}

        User Query:
        {user_query}

        ---

        ðŸ“Œ Output Format:  
        Return only a clean, numbered list of cleaning steps in plain English. Nothing else.
        """
        sample_parts = []
        for i, df in enumerate(state.raw_data):
            if isinstance(df, pd.DataFrame):
                sample_df = dynamic_sample(df)
                sample_str = f"File {i + 1} Sample:\n{sample_df.to_string(index=False)}"
                sample_parts.append(sample_str)

        sample_text = "\n\n".join(sample_parts)

        prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_message)
        ])

        prompt = prompt_template.invoke({
        "sample_data": sample_text,
        "user_query": state.question,
        "cleaning_recheck_suggestions": state.get("cleaning_recheck_suggestions", "")
        })

        result = self.llm.invoke(prompt)
        return {"cleaning_suggestion" : result}
    
    
    def cleaning_code(self, state: PythonAnalystState) -> dict:
        """Generate Python code for data cleaning based on suggestions.
        
        Args:
            state: Current state containing cleaning suggestions and raw data
            
        Returns:
            Dictionary containing generated cleaning code
            
        Raises:
            ValueError: If required state components are missing
        """
        if "cleaning_suggestion" not in state:
            raise ValueError("Cleaning suggestions not found in state")
            
        if "raw_data" not in state:
            raise ValueError("Raw data not found in state")
            
        prompt = PromptTemplate(
            template="""You are a data cleaning code generation agent.

    Your job is to generate a Python function based on the cleaning steps provided by the user:

    {recommended_steps}

    The function must be valid and executable on a pandas DataFrame.

    ---

    ðŸ”§ Requirements:
    - Use the sample below as the structure reference.
    - The function input should be a pandas DataFrame.
    - Return the cleaned DataFrame as `data_cleaned`.
    - Include necessary imports *inside* the function.
    - Wrap code in triple backticks with `python`.

    ðŸ“„ Sample data:
    {sample_text}
    """,
            input_variables=["recommended_steps", "sample_text"]
        )

        sample_parts = []
        for i, df in enumerate(state["raw_data"]):
            if isinstance(df, pd.DataFrame):
                sample_df = dynamic_sample(df)
                sample_parts.append(f"File {i + 1} Sample:\n{sample_df.to_string(index=False)}")

        sample_text = "\n\n".join(sample_parts)

        data_cleaning_agent = prompt | self.llm | PythonOutputParser()
        
        response = data_cleaning_agent.invoke({
            "recommended_steps": state["cleaning_suggestion"],
            "sample_text": sample_text
        })
        return {"cleaning_code":response}
    
    
    def cleaning_executor(self, state: PythonAnalystState) -> dict:
        import logging
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        cleaned_dfs = []
        code = state["cleaning_code"]

        for i, df in enumerate(state["raw_data"]):
            if not isinstance(df, pd.DataFrame):
                logger.warning("Item %(idx)s in raw_data is not a DataFrame, skipping...", 
                             {"idx": i + 1})
                continue
                
            local_vars = {"df": df.copy()}
            
            try:
                exec(code, {}, local_vars)
                
                cleaning_func = None
                for val in local_vars.values():
                    if callable(val):
                        cleaning_func = val
                        break
                        
                if cleaning_func is None:
                    raise ValueError("No callable function found in the cleaning code")
                    
                cleaned = cleaning_func(local_vars["df"])
                if not isinstance(cleaned, pd.DataFrame):
                    raise ValueError("Cleaning function did not return a DataFrame")
                    
                cleaned_dfs.append(cleaned)
                logger.info("Successfully cleaned DataFrame %(idx)s", {"idx": i + 1})
                
            except Exception as e:
                logger.error("Error cleaning DataFrame %(idx)s: %(error)s", 
                           {"idx": i + 1, "error": str(e)})
                logger.info("Using original DataFrame %(idx)s due to cleaning error", 
                          {"idx": i + 1})
                cleaned_dfs.append(df)
            
        return {"cleaned_data": cleaned_dfs}
    

    def check_node(self, state: PythonAnalystState) -> dict:
        prompt = PromptTemplate(
            template="""
    You are a data cleaning validation agent.

    Your job is to analyze a given pandas DataFrame and verify whether it has been cleaned according to a list of suggestions or required data cleaning steps.

    You must evaluate whether the DataFrame satisfies all the following conditions (as applicable):
    - Columns with >40% missing values have been removed.
    - Missing numeric values imputed with mean.
    - Missing categorical values imputed with mode.
    - Appropriate column data types.
    - Duplicates removed.
    - Rows with missing values removed.
    - Outliers removed using 3x IQR.

    ðŸ§¾ **Cleaned Data (Markdown Table)**:
    {cleaned_data}

    ðŸ“‹ **Cleaning Suggestions**:
    {suggestions}

    ---

    ðŸŽ¯ **Your Task**:
    Critically assess the cleaned data. Based on your analysis, answer the following:

    ðŸ§¾ **Output (JSON)**:
    {{
    "is_clean": True or False(Strictly Boolean Value),
    "missing_points": ["..."], 
    "reasoning": "Sharp, concise explanation with no fluff."
    }}
    """,
            input_variables=["cleaned_data", "suggestions"]
        )
        sample_parts = []
        for i, df in enumerate(state["cleaned_data"]):
            if isinstance(df, pd.DataFrame):
                sample_df = dynamic_sample(df)
                sample_parts.append(f"File {i + 1} Sample:\n{sample_df.to_string(index=False)}")
        cleaned_table = "\n\n".join(sample_parts)

        chain = prompt | self.llm | JsonOutputParser()
        response = chain.invoke({
            "cleaned_data": cleaned_table,
            "suggestions": state["cleaning_suggestion"]
        })
        
        if not isinstance(response, dict) or "is_clean" not in response:
            raise ValueError("Invalid response format from cleaning validation")
            
        return {
            "is_clean": response["is_clean"],
            "cleaning_recheck_suggestions": response
        }
    

    def next_route(self, state: PythonAnalystState) -> str:
        """Determine the next step in the data pipeline.
        
        Args:
            state: Current state containing cleaning validation result
            
        Returns:
            String indicating next route ("eda_suggestions" or "cleaning_suggestions")
            
        Raises:
            ValueError: If cleaning validation result is missing
        """
        if "is_clean" not in state:
            raise ValueError("Cleaning validation result not found in state")
            
        return "eda_suggestions" if state["is_clean"] else "cleaning_suggestions"
